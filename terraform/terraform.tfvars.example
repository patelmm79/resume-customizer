project = "your-gcp-project-id"
region = "us-central1"
service_name = "resume-customizer"
artifact_repo = "resume-customizer-repo"
# image: Leave empty to let Terraform construct the path automatically
# (recommended). Terraform will use: ${region}-docker.pkg.dev/${project}/${artifact_repo}/resume-customizer:latest
# Only set this if you want to override with a custom image path.
image = ""

# GitHub trigger settings (Cloud Build GitHub App integration)
# You must install the Google Cloud Build GitHub App on your repo and provide the installation id.
github_owner = "your-github-owner"
github_repo = "your-repo-name"
github_branch = "main"

# Use two-step apply: set create_runtime_bindings = false on first apply,
# then set to true after the Cloud Run runtime service account exists.
create_runtime_bindings = true

# Environment name for multi-instance deployments
# Use different values (dev, staging, prod) to isolate resources and state
environment = "dev"

# GCS Backend Configuration
# Set these when running terraform init for the first time:
#
#   terraform init \
#     -backend-config="bucket=your-project-id-terraform-state" \
#     -backend-config="prefix=resume-customizer/dev"
#
# Where:
#   - bucket: your GCS bucket name (must exist beforehand)
#   - prefix: path within bucket (one per environment)
#
# Create the bucket once per project:
#   gsutil mb gs://your-project-id-terraform-state


# -----------------------------------------------------------------------------
# LLM provider configuration (placeholders)
# - For secrets, set the Secret Manager secret name (recommended) or provide
#   the raw value here (not recommended for production).
# - Example secret naming convention: GEMINI_API_KEY-prod, ANTHROPIC_API_KEY-staging
# -----------------------------------------------------------------------------

# Which provider to enable by default (options: "gemini", "claude", "custom")
llm_provider = ""

# Google Gemini (recommended): either provide secret name or plain key
# If using Secret Manager, set to the secret resource name (e.g. "GEMINI_API_KEY-prod").
gemini_api_key_secret = ""
gemini_model = "gemini-2.0-flash-exp"

# Anthropic Claude
anthropic_api_key_secret = ""
claude_model = "claude-3-5-sonnet-20241022"

# Custom LLM (OpenAI-compatible / vLLM)
custom_llm_api_key_secret = ""
custom_llm_base_url = ""
custom_llm_model = ""

# Optional: lists of available models (comma-separated)
# gemini_models = "gemini-2.0-flash-exp,gemini-1.5-pro"
# claude_models = "claude-3-5-sonnet-20241022,claude-3-5-haiku-20241022"
# custom_models = "gpt-4-turbo-preview,gpt-4,gpt-3.5-turbo"

# -----------------------------------------------------------------------------
# Additional runtime tuning (custom LLM)
# These control retry/backoff behavior and context limits for custom LLMs.
# -----------------------------------------------------------------------------
# Max retry attempts for custom LLM (used when handling 503/warm-up)
custom_llm_max_retries = 5
# Initial retry delay in seconds (exponential backoff multiplier applied)
custom_llm_initial_retry_delay = 5.0
# Estimated model context limit (tokens) for custom LLMs
custom_llm_context_limit = 32768

# -----------------------------------------------------------------------------
# Secret Manager naming prefix for this application
# To avoid collisions with other projects/apps, set a prefix used when
# creating Secret Manager secret names (e.g. "resume_customizer-prod").
# Use in your CI script when creating or referencing secrets.
# -----------------------------------------------------------------------------
secret_prefix = "resume_customizer"

